{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gym-super-mario-bros\n",
    "%pip install -r requirements.txt \n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install 'stable-baselines4[extra]'\n",
    "%pip install optuna\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "env = gym.make('SuperMarioBros-v0') \n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "# Grey scale\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, env, num_episodes=5):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the model on a given environment.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to evaluate.\n",
    "    - env: The environment on which to evaluate the model.\n",
    "    - num_episodes: Number of episodes to run for the evaluation.\n",
    "\n",
    "    Returns:\n",
    "    - avg_reward: The average reward obtained over the evaluation episodes.\n",
    "    \"\"\"\n",
    "    total_rewards = 0.0\n",
    "    for ep in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        rewards = 0.0\n",
    "        while not done:\n",
    "            action = model.predict(obs)[0]\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            # print(reward)\n",
    "            rewards += reward[0]\n",
    "            if done:\n",
    "                break\n",
    "        total_rewards += rewards\n",
    "        print(f\"Episode {ep+1}: {rewards=:.2f}\")\n",
    "    avg_reward = total_rewards / num_episodes\n",
    "    return avg_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_uniform('lr', 1e-5, 8e-5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [512, 1024, 2048])\n",
    "    n_epochs = trial.suggest_int('n_epochs', 4, 10)\n",
    "    gae_lambda = trial.suggest_uniform('gae_lambda', 0.9, 0.95)\n",
    "    clip_range = trial.suggest_uniform('clip_range', 0.26, 0.3)\n",
    "    n_steps = trial.suggest_categorical('n_steps', [512, 1024])\n",
    "    gamma = trial.suggest_loguniform('gamma', 0.99, 0.999)\n",
    "    ent_coef = trial.suggest_loguniform('ent_coef', 0.00000001, 0.1)\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [64, 128, 256, 512])\n",
    "    policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[hidden_layer_sizes, hidden_layer_sizes])\n",
    "    # Initialize and train model with suggested hyperparameters\n",
    "    model = PPO(\"CnnPolicy\", \n",
    "                env, \n",
    "                verbose=1, \n",
    "                policy_kwargs=policy_kwargs, \n",
    "                gae_lambda=gae_lambda,\n",
    "                learning_rate=lr, n_steps=n_steps, \n",
    "                batch_size=batch_size, n_epochs=n_epochs, \n",
    "                clip_range=clip_range,\n",
    "                ent_coef=ent_coef, gamma=gamma, \n",
    "                tensorboard_log=\"logs\", \n",
    "                seed=43)\n",
    "    \n",
    "    model.learn(total_timesteps=45_000, tb_log_name=\"trial_{}\".format(trial.number))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    rewards = evaluate_model(model, env, num_episodes=3)\n",
    "    return rewards\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params  # Get the best hyperparameters\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Optionally, save best hyperparameters to a file\n",
    "import json\n",
    "with open(\"best_hyperparameters2.json\", \"a\") as f:\n",
    "    json.dump(best_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_trials = sorted(study.trials, key=lambda trial: trial.value, reverse=study.direction == 'maximize')\n",
    "\n",
    "with open(\"Trials4.txt\", \"a\") as f:\n",
    "    for trial in sorted_trials:\n",
    "        f.write(str(trial))\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trial_data = {\n",
    "    \"Trial Number\": [],\n",
    "    \"State\": [],\n",
    "    \"Values\": [],\n",
    "    \"Datetime Start\": [],\n",
    "    \"Datetime Complete\": [],\n",
    "    \"Learning Rate (lr)\": [],\n",
    "    \"Batch Size\": [],\n",
    "    \"Epochs (n_epochs)\": [],\n",
    "    \"Clip Range\": [],\n",
    "    \"Steps (n_steps)\": [],\n",
    "    \"Gamma\": [],\n",
    "    \"ent_coef\": [],\n",
    "    \"gae_lambda\": [],\n",
    "    \"hidden_layer_sizes\": [],\n",
    "}\n",
    "\n",
    "for trial in study.trials:  # Assuming study is your Optuna study variable\n",
    "    trial_data[\"Trial Number\"].append(trial.number)\n",
    "    trial_data[\"State\"].append(trial.state)\n",
    "    trial_data[\"Values\"].append(trial.values)\n",
    "    trial_data[\"Datetime Start\"].append(trial.datetime_start)\n",
    "    trial_data[\"Datetime Complete\"].append(trial.datetime_complete)\n",
    "    trial_data[\"Learning Rate (lr)\"].append(trial.params[\"lr\"])\n",
    "    trial_data[\"Batch Size\"].append(trial.params[\"batch_size\"])\n",
    "    trial_data[\"Epochs (n_epochs)\"].append(trial.params[\"n_epochs\"])\n",
    "    trial_data[\"Clip Range\"].append(trial.params[\"clip_range\"])\n",
    "    trial_data[\"Steps (n_steps)\"].append(trial.params[\"n_steps\"])\n",
    "    trial_data[\"Gamma\"].append(trial.params[\"gamma\"])\n",
    "    trial_data[\"ent_coef\"].append(trial.params[\"ent_coef\"])\n",
    "    trial_data[\"gae_lambda\"].append(trial.params[\"gae_lambda\"])\n",
    "    trial_data[\"hidden_layer_sizes\"].append(trial.params[\"hidden_layer_sizes\"])\n",
    "\n",
    "df_trials = pd.DataFrame(trial_data)\n",
    "\n",
    "excel_path = \"optuna_trials3.xlsx\"\n",
    "df_trials.to_excel(excel_path, index=False)\n",
    "\n",
    "print(f\"Excel file saved at: {excel_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
