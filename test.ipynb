{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush_ad/Code/mario/.conda/lib/python3.8/site-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/aayush_ad/Code/mario/.conda/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/aayush_ad/Code/mario/.conda/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/aayush_ad/Code/mario/.conda/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "import os\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "env = gym.make('SuperMarioBros-v0') \n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "# Grey scale\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mp = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Vectorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rl_model_3900000_steps.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush_ad/Code/mario/.conda/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/aayush_ad/Code/mario/.conda/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: rewards=2200.00\n",
      "Episode 2: rewards=2037.00\n",
      "Episode 3: rewards=1098.00\n",
      "Episode 4: rewards=1971.00\n",
      "Episode 5: rewards=2032.00\n",
      "Episode 6: rewards=1442.00\n",
      "Episode 7: rewards=1594.00\n",
      "Episode 8: rewards=2114.00\n",
      "Episode 9: rewards=1990.00\n",
      "Episode 10: rewards=2010.00\n",
      "Episode 11: rewards=1476.00\n",
      "Episode 12: rewards=1470.00\n",
      "Episode 13: rewards=1629.00\n",
      "Episode 14: rewards=1919.00\n",
      "Episode 15: rewards=2046.00\n",
      "Episode 16: rewards=1709.00\n",
      "Episode 17: rewards=2274.00\n",
      "Episode 18: rewards=1624.00\n",
      "Episode 19: rewards=1537.00\n",
      "Episode 20: rewards=2290.00\n",
      "Episode 21: rewards=1464.00\n",
      "Episode 22: rewards=1673.00\n",
      "Episode 23: rewards=1627.00\n",
      "Episode 24: rewards=1225.00\n",
      "Episode 25: rewards=3230.00\n",
      "Episode 26: rewards=2034.00\n",
      "Episode 27: rewards=1489.00\n",
      "Episode 28: rewards=3143.00\n",
      "Episode 29: rewards=2012.00\n",
      "Episode 30: rewards=1514.00\n",
      "Episode 31: rewards=2195.00\n",
      "rl_model_600000_steps.zip\n",
      "Episode 1: rewards=1644.00\n",
      "Episode 2: rewards=3521.00\n",
      "Episode 3: rewards=1892.00\n",
      "Episode 4: rewards=1571.00\n",
      "Episode 5: rewards=1863.00\n",
      "Episode 6: rewards=1884.00\n",
      "Episode 7: rewards=2932.00\n",
      "Episode 8: rewards=1636.00\n",
      "Episode 9: rewards=1046.00\n",
      "Episode 10: rewards=1412.00\n",
      "Episode 11: rewards=3049.00\n",
      "Episode 12: rewards=2722.00\n",
      "Episode 13: rewards=3337.00\n",
      "Episode 14: rewards=1531.00\n",
      "Episode 15: rewards=1422.00\n",
      "Episode 16: rewards=1525.00\n",
      "Episode 17: rewards=2053.00\n",
      "Episode 18: rewards=2781.00\n",
      "Episode 19: rewards=2149.00\n",
      "Episode 20: rewards=2129.00\n",
      "Episode 21: rewards=1199.00\n",
      "Episode 22: rewards=1059.00\n",
      "Episode 23: rewards=1424.00\n",
      "Episode 24: rewards=1986.00\n",
      "Episode 25: rewards=1885.00\n",
      "Episode 26: rewards=1931.00\n",
      "Episode 27: rewards=1946.00\n",
      "Episode 28: rewards=2290.00\n",
      "Episode 29: rewards=2120.00\n",
      "Episode 30: rewards=2768.00\n",
      "Episode 31: rewards=1952.00\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir():\n",
    "    model = PPO.load(file)\n",
    "    ep = 0\n",
    "    print(file)\n",
    "    while True:\n",
    "        ep = ep + 1 \n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        rewards = 0.0\n",
    "        while not done:\n",
    "            action = model.predict(obs)[0]\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            # print(reward)\n",
    "            rewards += reward[0]\n",
    "            if done:\n",
    "                break\n",
    "        print(f\"Episode {ep}: {rewards=:.2f}\")\n",
    "        best_mp[file] = max(best_mp.get(file, 0), rewards)\n",
    "        if rewards > 3100: # Victory\n",
    "            num[file] = num.get(file, 0) + 1\n",
    "        if ep > 30:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('SuperMarioBros-v0') \n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "# Grey scale\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rl_model_500000_steps.zip\n",
      "Episode 1: rewards=2201.00\n",
      "Episode 2: rewards=2191.00\n",
      "Episode 3: rewards=1948.00\n",
      "Episode 4: rewards=1487.00\n",
      "Episode 5: rewards=2215.00\n",
      "Episode 6: rewards=2317.00\n",
      "Episode 7: rewards=3074.00\n",
      "Episode 8: rewards=1513.00\n",
      "Episode 9: rewards=1189.00\n",
      "Episode 10: rewards=2454.00\n",
      "Episode 11: rewards=2390.00\n",
      "Episode 12: rewards=2397.00\n",
      "Episode 13: rewards=1899.00\n",
      "Episode 14: rewards=3706.00\n",
      "Episode 15: rewards=1595.00\n",
      "Episode 16: rewards=2663.00\n",
      "Episode 17: rewards=1673.00\n",
      "Episode 18: rewards=1977.00\n",
      "Episode 19: rewards=2174.00\n",
      "Episode 20: rewards=1632.00\n",
      "Episode 21: rewards=2342.00\n",
      "Episode 22: rewards=1472.00\n",
      "Episode 23: rewards=1586.00\n",
      "Episode 24: rewards=2279.00\n",
      "Episode 25: rewards=2616.00\n",
      "Episode 26: rewards=1616.00\n",
      "Episode 27: rewards=3095.00\n",
      "Episode 28: rewards=1492.00\n",
      "Episode 29: rewards=2428.00\n",
      "Episode 30: rewards=2949.00\n",
      "Episode 31: rewards=1471.00\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir():\n",
    "    if file.endswith('steps.zip'): \n",
    "        model = PPO.load(file)\n",
    "        ep = 0\n",
    "        print(file)\n",
    "        while True:\n",
    "            ep = ep + 1 \n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            rewards = 0.0\n",
    "            while not done:\n",
    "                action = model.predict(obs)[0]\n",
    "                obs, reward, done, info = env.step(action)\n",
    "                # print(reward)\n",
    "                rewards += reward[0]\n",
    "                if done:\n",
    "                    break\n",
    "            print(f\"Episode {ep}: {rewards=:.2f}\")\n",
    "            best_mp[file] = max(best_mp.get(file, 0), rewards)\n",
    "            if rewards > 3100:\n",
    "                num[file] = num.get(file, 0) + 1\n",
    "            if ep > 30:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rl_model_3900000_steps.zip': 2,\n",
       " 'rl_model_600000_steps.zip': 2,\n",
       " 'rl_model_500000_steps.zip': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rl_model_3900000_steps.zip': 3230.0,\n",
       " 'rl_model_600000_steps.zip': 3521.0,\n",
       " 'rl_model_500000_steps.zip': 3706.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
