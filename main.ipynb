{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym-super-mario-bros in ./.conda/lib/python3.8/site-packages (7.4.0)\n",
      "Requirement already satisfied: nes-py>=8.1.4 in ./.conda/lib/python3.8/site-packages (from gym-super-mario-bros) (8.2.1)\n",
      "Requirement already satisfied: gym>=0.17.2 in ./.conda/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./.conda/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.24.4)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in ./.conda/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.5.21)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in ./.conda/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (4.66.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.conda/lib/python3.8/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in ./.conda/lib/python3.8/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in ./.conda/lib/python3.8/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.conda/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (3.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gym==0.25.1 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (0.25.1)\n",
      "Requirement already satisfied: matplotlib>=2.0.2 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.7.4)\n",
      "Requirement already satisfied: nes-py>=4.0.0 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (8.2.1)\n",
      "Requirement already satisfied: numpy>=1.14.2 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.24.4)\n",
      "Requirement already satisfied: opencv-python>=3.4.0.12 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (4.9.0.80)\n",
      "Requirement already satisfied: pygame>=1.9.3 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (2.5.2)\n",
      "Requirement already satisfied: pyglet>=1.3.2 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.5.21)\n",
      "Requirement already satisfied: setuptools>=39.0.1 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (69.0.3)\n",
      "Requirement already satisfied: tqdm>=4.19.5 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (4.66.1)\n",
      "Requirement already satisfied: twine>=1.11.0 in ./.conda/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (4.0.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.conda/lib/python3.8/site-packages (from gym==0.25.1->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in ./.conda/lib/python3.8/site-packages (from gym==0.25.1->-r requirements.txt (line 1)) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in ./.conda/lib/python3.8/site-packages (from gym==0.25.1->-r requirements.txt (line 1)) (7.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.8/site-packages (from matplotlib>=2.0.2->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.8/site-packages (from matplotlib>=2.0.2->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.8/site-packages (from matplotlib>=2.0.2->-r requirements.txt (line 2)) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.conda/lib/python3.8/site-packages (from matplotlib>=2.0.2->-r requirements.txt (line 2)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.8/site-packages (from matplotlib>=2.0.2->-r requirements.txt (line 2)) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.conda/lib/python3.8/site-packages (from matplotlib>=2.0.2->-r requirements.txt (line 2)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/lib/python3.8/site-packages (from matplotlib>=2.0.2->-r requirements.txt (line 2)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.8/site-packages (from matplotlib>=2.0.2->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.conda/lib/python3.8/site-packages (from matplotlib>=2.0.2->-r requirements.txt (line 2)) (6.1.1)\n",
      "Requirement already satisfied: pkginfo>=1.8.1 in ./.conda/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 10)) (1.9.6)\n",
      "Requirement already satisfied: readme-renderer>=35.0 in ./.conda/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 10)) (42.0)\n",
      "Requirement already satisfied: requests>=2.20 in ./.conda/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 10)) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in ./.conda/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 10)) (1.0.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./.conda/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: keyring>=15.1 in ./.conda/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 10)) (24.3.0)\n",
      "Requirement already satisfied: rfc3986>=1.4.0 in ./.conda/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 10)) (2.0.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in ./.conda/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 10)) (13.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.conda/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gym==0.25.1->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: jaraco.classes in ./.conda/lib/python3.8/site-packages (from keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 10)) (3.3.0)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in ./.conda/lib/python3.8/site-packages (from keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 10)) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in ./.conda/lib/python3.8/site-packages (from keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 10)) (0.8.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.2->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: nh3>=0.2.14 in ./.conda/lib/python3.8/site-packages (from readme-renderer>=35.0->twine>=1.11.0->-r requirements.txt (line 10)) (0.2.15)\n",
      "Requirement already satisfied: docutils>=0.13.1 in ./.conda/lib/python3.8/site-packages (from readme-renderer>=35.0->twine>=1.11.0->-r requirements.txt (line 10)) (0.20.1)\n",
      "Requirement already satisfied: Pygments>=2.5.1 in ./.conda/lib/python3.8/site-packages (from readme-renderer>=35.0->twine>=1.11.0->-r requirements.txt (line 10)) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.8/site-packages (from requests>=2.20->twine>=1.11.0->-r requirements.txt (line 10)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.8/site-packages (from requests>=2.20->twine>=1.11.0->-r requirements.txt (line 10)) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.8/site-packages (from requests>=2.20->twine>=1.11.0->-r requirements.txt (line 10)) (2023.11.17)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.conda/lib/python3.8/site-packages (from rich>=12.0.0->twine>=1.11.0->-r requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in ./.conda/lib/python3.8/site-packages (from rich>=12.0.0->twine>=1.11.0->-r requirements.txt (line 10)) (4.9.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.conda/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine>=1.11.0->-r requirements.txt (line 10)) (0.1.2)\n",
      "Requirement already satisfied: cryptography>=2.0 in ./.conda/lib/python3.8/site-packages (from SecretStorage>=3.2->keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 10)) (42.0.1)\n",
      "Requirement already satisfied: more-itertools in ./.conda/lib/python3.8/site-packages (from jaraco.classes->keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 10)) (10.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.conda/lib/python3.8/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: pycparser in ./.conda/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 10)) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in ./.conda/lib/python3.8/site-packages (2.1.2+cu118)\n",
      "Requirement already satisfied: torchvision in ./.conda/lib/python3.8/site-packages (0.16.2+cu118)\n",
      "Requirement already satisfied: torchaudio in ./.conda/lib/python3.8/site-packages (2.1.2+cu118)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.8/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./.conda/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./.conda/lib/python3.8/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in ./.conda/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.conda/lib/python3.8/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in ./.conda/lib/python3.8/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.8/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/lib/python3.8/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.conda/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.8/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.8/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.8/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.8/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.conda/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: stable-baselines3[extra] in ./.conda/lib/python3.8/site-packages (2.2.1)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.13 in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.1.2+cu118)\n",
      "Requirement already satisfied: cloudpickle in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (3.7.4)\n",
      "Requirement already satisfied: opencv-python in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.9.0.80)\n",
      "Requirement already satisfied: pygame in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.5.2)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.14.0)\n",
      "Requirement already satisfied: psutil in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (5.9.8)\n",
      "Requirement already satisfied: tqdm in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.66.1)\n",
      "Requirement already satisfied: rich in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (13.7.0)\n",
      "Requirement already satisfied: shimmy~=1.3.0 in ./.conda/lib/python3.8/site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pillow in ./.conda/lib/python3.8/site-packages (from stable-baselines3[extra]) (10.2.0)\n",
      "Requirement already satisfied: autorom~=0.6.1 in ./.conda/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: click in ./.conda/lib/python3.8/site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (8.1.7)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.8/site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.31.0)\n",
      "Requirement already satisfied: importlib-resources in ./.conda/lib/python3.8/site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (6.1.1)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in ./.conda/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./.conda/lib/python3.8/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./.conda/lib/python3.8/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in ./.conda/lib/python3.8/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (7.0.1)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in ./.conda/lib/python3.8/site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.60.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.5.2)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (69.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in ./.conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.42.0)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.9.0)\n",
      "Requirement already satisfied: sympy in ./.conda/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
      "Requirement already satisfied: networkx in ./.conda/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.0)\n",
      "Requirement already satisfied: jinja2 in ./.conda/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.conda/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in ./.conda/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.conda/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.conda/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2023.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.conda/lib/python3.8/site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.conda/lib/python3.8/site-packages (from rich->stable-baselines3[extra]) (2.17.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.conda/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.conda/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.conda/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.8/site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.8/site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.8/site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.8/site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.conda/lib/python3.8/site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./.conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym-super-mario-bros\n",
    "%pip install -r requirements.txt \n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install 'stable-baselines4[extra]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush_ad/Code/mario/.conda/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "env = gym.make('SuperMarioBros-v0') \n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "# Grey scale\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True\n",
    "env.reset()\n",
    "for step in range(500):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step([action])\n",
    "    # env.render()\n",
    "    if done:\n",
    "       state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, env, num_episodes=5):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the model on a given environment.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to evaluate.\n",
    "    - env: The environment on which to evaluate the model.\n",
    "    - num_episodes: Number of episodes to run for the evaluation.\n",
    "\n",
    "    Returns:\n",
    "    - avg_reward: The average reward obtained over the evaluation episodes.\n",
    "    \"\"\"\n",
    "    total_rewards = 0.0\n",
    "    for ep in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        rewards = 0.0\n",
    "        while not done:\n",
    "            action = model.predict(obs)[0]\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            # print(reward)\n",
    "            rewards += reward[0]\n",
    "            if done:\n",
    "                break\n",
    "        total_rewards += rewards\n",
    "        print(f\"Episode {ep+1}: {rewards=:.2f}\")\n",
    "    avg_reward = total_rewards / num_episodes\n",
    "    return avg_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_mario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, env, num_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to logs/time=2000000, lr=3.65514567388135e-05, ent_coef=0.00290321362474043, batch_size=2048, n_epochs=10, clip_range=0.279291059130489, n_steps=1024, gamma=0.9951330516817_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush_ad/Code/mario/.conda/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/aayush_ad/Code/mario/.conda/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 273  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 14   |\n",
      "|    total_timesteps | 4096 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001818073 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | -0.00148    |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 7.86        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 37           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 324          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015641022 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.279        |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | -0.00545     |\n",
      "|    learning_rate        | 3.66e-05     |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 474         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010625248 |\n",
      "|    clip_fraction        | 0.00022     |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -2.47       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 5.76        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011865283 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | -0.075      |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 31           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 771          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037400862 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.279        |\n",
      "|    entropy_loss         | -2.37        |\n",
      "|    explained_variance   | 0.354        |\n",
      "|    learning_rate        | 3.66e-05     |\n",
      "|    loss                 | 4.94         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 9.91         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 923         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012592381 |\n",
      "|    clip_fraction        | 0.00923     |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -2.34       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.000185   |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1074        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006892273 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 4.02        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 8.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1229        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017906291 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1382         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078021013 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.279        |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.153        |\n",
      "|    learning_rate        | 3.66e-05     |\n",
      "|    loss                 | 2.69         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000865    |\n",
      "|    value_loss           | 7.77         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1536        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015006798 |\n",
      "|    clip_fraction        | 0.00659     |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1690        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010055677 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 6.86        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1844        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006048883 |\n",
      "|    clip_fraction        | 0.00134     |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.000291   |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1997        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011404734 |\n",
      "|    clip_fraction        | 0.00107     |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.0241      |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 2.47        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    value_loss           | 4.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 2151        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029417358 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 2304        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017034963 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 6.81        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 2453        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011336645 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2586        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.088050514 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -0.0451     |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 4.88        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.00865     |\n",
      "|    value_loss           | 4.66        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2717         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147243515 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.279        |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 3.66e-05     |\n",
      "|    loss                 | 55.4         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000867    |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2847        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019823093 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 52.9        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.000792    |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 2981         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070329322 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.279        |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.0161      |\n",
      "|    learning_rate        | 3.66e-05     |\n",
      "|    loss                 | 2.44         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000729    |\n",
      "|    value_loss           | 9.5          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 3111        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018088214 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 3254        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019700052 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.0194     |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 3.89        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 7.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 3396        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018720075 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00051     |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 3542        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.091489315 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.0116     |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.00941     |\n",
      "|    value_loss           | 6.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 3681        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004007243 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.000178   |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 3823        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014585139 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -0.0205     |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 2.89        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 3958         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022874041 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.279        |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 3.66e-05     |\n",
      "|    loss                 | 45.7         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000727    |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 4087        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004255038 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 9.18        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 4229         |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015449516 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.279        |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | 0.789        |\n",
      "|    learning_rate        | 3.66e-05     |\n",
      "|    loss                 | 49           |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -6.76e-06    |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 4360        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003895247 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -0.00903    |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00096    |\n",
      "|    value_loss           | 6.94        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 29        |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 4495      |\n",
      "|    total_timesteps      | 131072    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0245868 |\n",
      "|    clip_fraction        | 0.0164    |\n",
      "|    clip_range           | 0.279     |\n",
      "|    entropy_loss         | -1.45     |\n",
      "|    explained_variance   | 0.755     |\n",
      "|    learning_rate        | 3.66e-05  |\n",
      "|    loss                 | 36.7      |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -0.00285  |\n",
      "|    value_loss           | 89.7      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 4628         |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017086363 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.279        |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | -0.037       |\n",
      "|    learning_rate        | 3.66e-05     |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | 0.000169     |\n",
      "|    value_loss           | 5.63         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 4758        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016461408 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.279       |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 3.66e-05    |\n",
      "|    loss                 | 54.6        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "time = 1_000_000\n",
    "lr = 0.0000365514567388135\n",
    "batch_size = 2048\n",
    "n_epochs = 10\n",
    "clip_range = 0.279291059130489\n",
    "n_steps = 1024\n",
    "gamma = 0.9951330516817\n",
    "ent_coef = 0.00290321362474043\n",
    "\n",
    "seed = 43\n",
    "callback = CheckpointCallback(save_freq=100_000, save_path='./gym/')\n",
    "hyperparam = f'{time=}, {lr=}, {ent_coef=}, {batch_size=}, {n_epochs=}, {clip_range=}, {n_steps=}, {gamma=}'\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, learning_rate=lr, n_steps=n_steps, ent_coef=ent_coef, batch_size=batch_size, n_epochs=n_epochs, clip_range=clip_range, gamma=gamma, tensorboard_log=\"logs\", seed=seed)\n",
    "model.learn(total_timesteps=time, callback=callback, tb_log_name=hyperparam)\n",
    "\n",
    "model.save(\"ppo_mario_{hyperparam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=PPO.load('gym/rl_model_1100000_steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: rewards=1242.00\n",
      "Episode 2: rewards=1519.00\n",
      "Episode 3: rewards=1420.00\n",
      "Episode 4: rewards=1136.00\n",
      "Episode 5: rewards=1118.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1287.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, env, num_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('gym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rl_model_100000_steps.zip',\n",
       " 'best_model.zip',\n",
       " 'rl_model_1400000_steps.zip',\n",
       " 'rl_model_900000_steps.zip',\n",
       " 'rl_model_1200000_steps.zip',\n",
       " 'rl_model_500000_steps.zip',\n",
       " 'rl_model_1500000_steps.zip',\n",
       " 'rl_model_400000_steps.zip',\n",
       " 'rl_model_700000_steps.zip',\n",
       " 'rl_model_200000_steps.zip',\n",
       " 'rl_model_1600000_steps.zip',\n",
       " 'rl_model_1700000_steps.zip',\n",
       " 'rl_model_1100000_steps.zip',\n",
       " 'rl_model_1800000_steps.zip',\n",
       " 'rl_model_800000_steps.zip',\n",
       " 'rl_model_1000000_steps.zip',\n",
       " 'rl_model_900000_steps (2).zip',\n",
       " 'rl_model_1300000_steps.zip',\n",
       " 'rl_model_600000_steps.zip',\n",
       " 'rl_model_300000_steps.zip']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rl_model_100000_steps.zip\n",
      "Episode 1: rewards=755.00\n",
      "Episode 2: rewards=632.00\n",
      "Episode 3: rewards=755.00\n",
      "Episode 4: rewards=504.00\n",
      "Episode 5: rewards=632.00\n",
      "best_model.zip\n",
      "Episode 1: rewards=752.00\n",
      "Episode 2: rewards=710.00\n",
      "Episode 3: rewards=431.00\n",
      "Episode 4: rewards=503.00\n",
      "Episode 5: rewards=504.00\n",
      "rl_model_1400000_steps.zip\n",
      "Episode 1: rewards=1215.00\n",
      "Episode 2: rewards=961.00\n",
      "Episode 3: rewards=1408.00\n",
      "Episode 4: rewards=1373.00\n",
      "Episode 5: rewards=1022.00\n",
      "rl_model_900000_steps.zip\n",
      "Episode 1: rewards=1367.00\n",
      "Episode 2: rewards=1275.00\n",
      "Episode 3: rewards=1445.00\n",
      "Episode 4: rewards=1368.00\n",
      "Episode 5: rewards=1022.00\n",
      "rl_model_1200000_steps.zip\n",
      "Episode 1: rewards=1048.00\n",
      "Episode 2: rewards=1064.00\n",
      "Episode 3: rewards=1147.00\n",
      "Episode 4: rewards=1003.00\n",
      "Episode 5: rewards=1365.00\n",
      "rl_model_500000_steps.zip\n",
      "Episode 1: rewards=1422.00\n",
      "Episode 2: rewards=961.00\n",
      "Episode 3: rewards=1298.00\n",
      "Episode 4: rewards=1026.00\n",
      "Episode 5: rewards=1387.00\n",
      "rl_model_1500000_steps.zip\n",
      "Episode 1: rewards=1290.00\n",
      "Episode 2: rewards=1035.00\n",
      "Episode 3: rewards=1334.00\n",
      "Episode 4: rewards=1137.00\n",
      "Episode 5: rewards=1268.00\n",
      "rl_model_400000_steps.zip\n",
      "Episode 1: rewards=680.00\n",
      "Episode 2: rewards=680.00\n",
      "Episode 3: rewards=680.00\n",
      "Episode 4: rewards=680.00\n",
      "Episode 5: rewards=680.00\n",
      "rl_model_700000_steps.zip\n",
      "Episode 1: rewards=987.00\n",
      "Episode 2: rewards=1151.00\n",
      "Episode 3: rewards=1385.00\n",
      "Episode 4: rewards=808.00\n",
      "Episode 5: rewards=1328.00\n",
      "rl_model_200000_steps.zip\n",
      "Episode 1: rewards=632.00\n",
      "Episode 2: rewards=783.00\n",
      "Episode 3: rewards=632.00\n",
      "Episode 4: rewards=1006.00\n",
      "Episode 5: rewards=504.00\n",
      "rl_model_1600000_steps.zip\n",
      "Episode 1: rewards=680.00\n",
      "Episode 2: rewards=743.00\n",
      "Episode 3: rewards=1041.00\n",
      "Episode 4: rewards=757.00\n",
      "Episode 5: rewards=1040.00\n",
      "rl_model_1700000_steps.zip\n",
      "Episode 1: rewards=1083.00\n",
      "Episode 2: rewards=1234.00\n",
      "Episode 3: rewards=922.00\n",
      "Episode 4: rewards=1266.00\n",
      "Episode 5: rewards=1070.00\n",
      "rl_model_1100000_steps.zip\n",
      "Episode 1: rewards=808.00\n",
      "Episode 2: rewards=1451.00\n",
      "Episode 3: rewards=1567.00\n",
      "Episode 4: rewards=1367.00\n",
      "Episode 5: rewards=1139.00\n",
      "rl_model_1800000_steps.zip\n",
      "Episode 1: rewards=1120.00\n",
      "Episode 2: rewards=1103.00\n",
      "Episode 3: rewards=1446.00\n",
      "Episode 4: rewards=1248.00\n",
      "Episode 5: rewards=808.00\n",
      "rl_model_800000_steps.zip\n",
      "Episode 1: rewards=1287.00\n",
      "Episode 2: rewards=814.00\n",
      "Episode 3: rewards=794.00\n",
      "Episode 4: rewards=1137.00\n",
      "Episode 5: rewards=1372.00\n",
      "rl_model_1000000_steps.zip\n",
      "Episode 1: rewards=992.00\n",
      "Episode 2: rewards=814.00\n",
      "Episode 3: rewards=808.00\n",
      "Episode 4: rewards=808.00\n",
      "Episode 5: rewards=1012.00\n",
      "rl_model_1300000_steps.zip\n",
      "Episode 1: rewards=992.00\n",
      "Episode 2: rewards=814.00\n",
      "Episode 3: rewards=808.00\n",
      "Episode 4: rewards=632.00\n",
      "Episode 5: rewards=1136.00\n",
      "rl_model_600000_steps.zip\n",
      "Episode 1: rewards=1111.00\n",
      "Episode 2: rewards=1092.00\n",
      "Episode 3: rewards=1366.00\n",
      "Episode 4: rewards=1423.00\n",
      "Episode 5: rewards=951.00\n",
      "rl_model_300000_steps.zip\n",
      "Episode 1: rewards=808.00\n",
      "Episode 2: rewards=504.00\n",
      "Episode 3: rewards=1281.00\n",
      "Episode 4: rewards=1285.00\n",
      "Episode 5: rewards=632.00\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir():\n",
    "    if file.endswith('.zip') and file != 'rl_model_900000_steps (2).zip':\n",
    "        model = PPO.load(file)\n",
    "        print(file)\n",
    "        # evaluate_model(model, env, num_episodes=5)\n",
    "        mp[file] = evaluate_model(model, env, num_episodes=5)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rl_model_100000_steps.zip': 655.6,\n",
       " 'best_model.zip': 580.0,\n",
       " 'rl_model_1400000_steps.zip': 1195.8,\n",
       " 'rl_model_900000_steps.zip': 1295.4,\n",
       " 'rl_model_1200000_steps.zip': 1125.4,\n",
       " 'rl_model_500000_steps.zip': 1218.8,\n",
       " 'rl_model_1500000_steps.zip': 1212.8,\n",
       " 'rl_model_400000_steps.zip': 680.0,\n",
       " 'rl_model_700000_steps.zip': 1131.8,\n",
       " 'rl_model_200000_steps.zip': 711.4,\n",
       " 'rl_model_1600000_steps.zip': 852.2,\n",
       " 'rl_model_1700000_steps.zip': 1115.0,\n",
       " 'rl_model_1100000_steps.zip': 1266.4,\n",
       " 'rl_model_1800000_steps.zip': 1145.0,\n",
       " 'rl_model_800000_steps.zip': 1080.8,\n",
       " 'rl_model_1000000_steps.zip': 886.8,\n",
       " 'rl_model_1300000_steps.zip': 876.4,\n",
       " 'rl_model_600000_steps.zip': 1188.6,\n",
       " 'rl_model_300000_steps.zip': 902.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('rl_model_900000_steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: rewards=1367.00\n",
      "Episode 2: rewards=1275.00\n",
      "Episode 3: rewards=1445.00\n",
      "Episode 4: rewards=1368.00\n",
      "Episode 5: rewards=1022.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1295.4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, env, num_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
